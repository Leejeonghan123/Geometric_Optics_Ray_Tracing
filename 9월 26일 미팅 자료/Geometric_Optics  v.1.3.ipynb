{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc499f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1f154f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute '_unique_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m     loss \u001b[38;5;241m=\u001b[39m get_loss(PINN_list, input_data)\n\u001b[0;32m     68\u001b[0m g \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, trainable)\n\u001b[1;32m---> 69\u001b[0m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py:1140\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[1;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[0;32m   1139\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[1;32m-> 1140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py:621\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[1;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(scope_name):\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[0;32m    619\u001b[0m         \u001b[38;5;66;03m# Lift variable creation to init scope to avoid environment\u001b[39;00m\n\u001b[0;32m    620\u001b[0m         \u001b[38;5;66;03m# issues.\u001b[39;00m\n\u001b[1;32m--> 621\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[0;32m    623\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m optimizer_utils\u001b[38;5;241m.\u001b[39mfilter_empty_gradients(grads_and_vars)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\adam.py:131\u001b[0m, in \u001b[0;36mAdam.build\u001b[1;34m(self, var_list)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, var_list):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;124;03m\"\"\"Initialize optimizer variables.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    Adam optimizer has 3 types of variables: momentums, velocities and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m      var_list: list of model variables to build Adam variables on.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_built\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_built:\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py:399\u001b[0m, in \u001b[0;36m_BaseOptimizer.build\u001b[1;34m(self, var_list)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_built\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_variables_moving_average \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py:425\u001b[0m, in \u001b[0;36m_BaseOptimizer._build_index_dict\u001b[1;34m(self, var_list)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(var_list):\n\u001b[1;32m--> 425\u001b[0m     var_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_var_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_dict[var_key] \u001b[38;5;241m=\u001b[39m i\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py:1091\u001b[0m, in \u001b[0;36mOptimizer._var_key\u001b[1;34m(self, variable)\u001b[0m\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1084\u001b[0m     tf_utils\u001b[38;5;241m.\u001b[39mis_extension_type(variable)\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(variable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;66;03m# For ResourceVariables, the _distributed_container attribute\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;66;03m# is added to their handle tensors.\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m     variable \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39m_distributed_container()\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_var_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py:145\u001b[0m, in \u001b[0;36m_BaseOptimizer._var_key\u001b[1;34m(self, variable)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m\"\"\"Get a unique identifier of the given variable.\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Get the distributed variable if it exists.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# TODO(b/199214315): replace _unique_id with ref() after fixing ref()\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# issues on AggregatingVariable.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique_id\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute '_unique_id'"
     ]
    }
   ],
   "source": [
    "R = tf.Variable(0.5, trainable = False)\n",
    "center = tf.Variable([[0.,0.,0.]], trainable = False)\n",
    "\n",
    "x = tf.ones((10,1)) * -5\n",
    "y = tf.random.uniform((10,1), -5, 5)\n",
    "z = tf.zeros((10,1))\n",
    "psi = tf.ones((10,1)) * np.pi/2\n",
    "theta = tf.random.uniform((10,1), -np.pi/2, np.pi/2)\n",
    "\n",
    "init_pos = tf.concat((x,y,z,psi,theta), axis=1)\n",
    "\n",
    "def spherical_to_vec(inputs):\n",
    "    x, y, z, psi, theta = tf.split(inputs, 5, axis=1)\n",
    "    r_x = np.sin(psi) * np.cos(theta)\n",
    "    r_y = np.sin(psi) * np.sin(theta)\n",
    "    r_z = tf.cos(theta)\n",
    "    return tf.concat((x, y, z, r_x, r_y, r_z), axis=1)\n",
    "\n",
    "input_data = spherical_to_vec(init_pos)\n",
    "\n",
    "def PINN():\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape=(6,)),\n",
    "            tf.keras.layers.Dense(10, activation='relu', kernel_initializer='glorot_normal', name='hidden1'),\n",
    "            tf.keras.layers.Dense(10, activation='relu', kernel_initializer='glorot_normal', name='hidden2'),\n",
    "            tf.keras.layers.Dense(1, name='output')\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "PINN_list = [PINN() for _ in range(10)]\n",
    "\n",
    "def prop_(inputs):\n",
    "    x, y, z, r_x, r_y, r_z, t = tf.split(inputs, 7, axis=1)\n",
    "    x_prop = x + r_x * t\n",
    "    y_prop = y + r_y * t\n",
    "    z_prop = z + r_z * t\n",
    "    return tf.concat((x_prop,y_prop,z_prop), axis=1)\n",
    "\n",
    "def intersection(inputs):\n",
    "    inter_ = tf.square(tf.reduce_sum(tf.square(inputs- center), keepdims=True) - tf.square(R)) \n",
    "    return inter_\n",
    "\n",
    "def get_loss(PINN_list, input_data):\n",
    "    \n",
    "    pred_t = [PINN_list[i](input_unit) for i, input_unit in enumerate(tf.split(input_data,10))]\n",
    "    \n",
    "    total_inp = [tf.concat([tf.reshape(input_unit,(1,-1)), t], axis=1) for input_unit, t in zip(input_data, pred_t)]\n",
    "    \n",
    "    prop = [prop_(inp) for inp in total_inp]\n",
    "    \n",
    "    inter_loss = [intersection(prop_unit) for prop_unit in prop]\n",
    "    \n",
    "    prop_x_loss = [tf.math.maximum(-prop_unit[:,0:1], 0) for prop_unit in prop]\n",
    "    \n",
    "    total_loss = [inter + prop_x for inter, prop_x in zip(inter_loss, prop_x_loss)]\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "lr = 1e-2\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        trainable = [PINN_list[i].trainable_weights for i in range(10)]\n",
    "\n",
    "        loss = get_loss(PINN_list, input_data)\n",
    "    g = tape.gradient(loss, trainable)\n",
    "    optim.apply_gradients(zip(g, trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edebca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
